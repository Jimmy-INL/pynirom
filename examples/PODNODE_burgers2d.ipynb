{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308436a5",
   "metadata": {},
   "source": [
    "### Notebook for constructiong POD-NODE NIROM approximation for a 2D Burgers' example\n",
    "\n",
    "A collection of high-fidelity snapshots are generated that sufficiently capture the time-dynamics of the simulation. POD is adopted to define a reduced basis space for the high-fidelity snaphosts. The evolution of the time dynamics in the POD-latent space is modeled using Neural ODEs (NODE).  \n",
    "\n",
    "Firedrake is used as the high-fidelity model for solving the 2D viscous Burgers equation to generate snapshots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f787c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading modules\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import scipy\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import platform\n",
    "print(\"Python \"+str(platform.python_version()))\n",
    "import importlib\n",
    "from importlib import reload as reload\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow \"+ str(tf.__version__))\n",
    "if tf.__version__ == '1.15.0':\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "elif tf.__version__.split('.')[0] == 2: \n",
    "    print(\"Setting Keras backend datatype\")\n",
    "    tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "from tfdiffeq import odeint,odeint_adjoint\n",
    "from tfdiffeq.adjoint import odeint as adjoint_odeint\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "np.random.seed(0)\n",
    "\n",
    "basedir   = os.getcwd()\n",
    "srcdir    = os.path.join(basedir,'../pynirom/')\n",
    "workdir   = os.path.join(basedir,'../examples/')\n",
    "datadir   = os.path.join(basedir,'../data/')\n",
    "figdir    = os.path.join(basedir,'../figures/podnode')\n",
    "nodedir   = os.path.join(basedir,'../data/')\n",
    "savedir = nodedir+'burgers2d/current'\n",
    "\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)\n",
    "\n",
    "import pynirom\n",
    "from pynirom.pod import pod_utils as pod\n",
    "from pynirom.rbf import plotting as rpu\n",
    "from pynirom.utils import data_utils as du\n",
    "from pynirom.node import main as nd\n",
    "from pynirom.node import plotting as pu\n",
    "from pynirom.node import node as node\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fff0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu:0'           # select gpu:# or cpu:#\n",
    "purpose= 'train'           #'train' to train a new model, \n",
    "                           # 'retrain' to start training from an existing model, and \n",
    "                           # 'eval' to load a pre-trained model for evaluation \n",
    "pre_trained_dir = savedir+'/model_weights/' #If 'eval' specify path for pretrained model\n",
    "stacking = True            #If True, Specify new stacking order of latent space vector\n",
    "stack_order = 'v_x,v_y'    #If stacking = True, specify the stacking order of the latent space vector\n",
    "scale_time = True          #Scale time or not (Normalize)\n",
    "scale_states = False       #Scale states or not \n",
    "scaling_method = 'centered' #Scaling method: 'centered', 'minmax' or 'maxabs'\n",
    "augmented,aug_dims = (False,5) #Augmented or not and size of augmentation\n",
    "N_layers = int(1)          #Only four layers supported as of now.\n",
    "N_neurons = int(40)        #Number of neurons per layer\n",
    "act_f = 'tanh'             #Activation Function ('linear', 'tanh', 'sigmoid',...), default='tanh'\n",
    "learning_rate_decay = True #Use decaying learning rate or not\n",
    "initial_learning_rate = float(0.01) #If 'learning_rate_decay = False' then this is the fixed learning rate\n",
    "decay_steps = int(401)     #Number of steps for learning rate decay\n",
    "decay_rate = float(0.9)    #Rate of learning rate decay\n",
    "staircase_opt = True       #True for staircase decay and False for exponential\n",
    "optimizer = 'RMSprop'      #See pynirom.node.node.set_optimizer() for options\n",
    "use_adjoint = False        #Use adjoint method or not\n",
    "solver = 'euler'           #Specify ODE solver. See tfdiffeq README for available options \n",
    "use_minibatch, batch_size = (False,256) #Use minibatch or not and batch size\n",
    "epochs = int(2000)         #Number of epochs of training\n",
    "\n",
    "\n",
    "print(\"\\n***** Runtime parameters: ******\\n\")\n",
    "print(f'Mode = {purpose}, Scaling = {scale_states}, Augmenting = {augmented}, Adjoint = {use_adjoint}')\n",
    "print(f'Solver = {solver}, Optimizer = {optimizer}, Stacking order = {stack_order}, Epochs = {epochs}')\n",
    "print(f'# Layers = {N_layers}, # Neurons per layer = {N_neurons}, Activation fn = {act_f}')\n",
    "if use_minibatch:\n",
    "    print(f'Use minibatch = {use_minibatch}, Batch size = {batch_size}')\n",
    "if learning_rate_decay:\n",
    "    print(f'Init LR = {initial_learning_rate}, # LR decay steps = {decay_steps}, LR decay rate = {decay_rate}')\n",
    "else:\n",
    "    print(f'Fixed LR = {initial_learning_rate}')\n",
    "print('**********************************\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236eb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ Import Snapshot data -------------------\n",
    "data = np.load(datadir + 'Burgers2D_Re1000_Nn3721_Nt1500.npz')\n",
    "\n",
    "print('HFM data has {0} snapshots of dimension {1} for p,u and v, spanning times [{2}, {3}]'.format(\n",
    "                    data['time'].shape[0],data['v_x'].shape[0],\n",
    "                    data['time'][0], data['time'][-1]))\n",
    "\n",
    "\n",
    "## ------- Prepare training snapshots ----------------\n",
    "print('\\n-------Prepare training and testing data---------')\n",
    "soln_names = ['v_x', 'v_y']\n",
    "nodes = data['nodes'];  \n",
    "triangles = data['elems']; \n",
    "snap_start = 10\n",
    "T_end = 1500.0        ### 5 seconds\n",
    "snap_incr = 4\n",
    "\n",
    "snap_train, times_train = du.prepare_data(data, soln_names, start_skip=snap_start, T_end=T_end, incr=snap_incr)\n",
    "print('Using {0} training snapshots for time interval [{1},{2}] seconds'.format(times_train.shape[0],\n",
    "                                        times_train[0], times_train[-1]))\n",
    "\n",
    "## ------- Prepare testing snapshots ----------------\n",
    "pred_incr = snap_incr - 3\n",
    "snap_pred_true, times_predict = du.prepare_data(data, soln_names, start_skip=snap_start, incr=pred_incr)\n",
    "print('Using {0} testing snapshots for time interval [{1},{2}] seconds'.format(times_predict.shape[0],\n",
    "                                        times_predict[0], times_predict[-1]))\n",
    "\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ Compute the POD basis using the training snapshots------------------\n",
    "trunc_lvl = 0.99\n",
    "snap_norm, snap_mean, U, D, W = pod.compute_pod_multicomponent(snap_train)\n",
    "nw, U_r = pod.compute_trunc_basis(D, U, eng_cap = trunc_lvl)\n",
    "\n",
    "### ------ Compute the POD coefficients for training snapshots------------------\n",
    "Z_train = pod.project_onto_basis(snap_train, U_r, snap_mean)\n",
    "\n",
    "\n",
    "### ------ Compute the POD coefficients for the truth snapshots on the prediction interval------------------\n",
    "Z_pred_true = pod.project_onto_basis(snap_pred_true, U_r, snap_mean)\n",
    "\n",
    "npod_total = 0\n",
    "for key in soln_names:\n",
    "    npod_total+=nw[key]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpu.plot_sing_val(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c91a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- Setup NODE input data\n",
    "\n",
    "NODE = nd.NODEBase(device=device)\n",
    "true_state_array, true_pred_state_array, init_state, state_len, dt_train, dt_predict = \\\n",
    "        NODE.prepare_input_data(Z_train, nw, times_train, stack_order, times_predict, Z_pred_true)\n",
    "\n",
    "print(\"Training NODE using %d modes for %d time steps with %.3f <= t <= %.3f and dt = %.3f\"%(state_len,\n",
    "                             true_state_array.shape[0], times_train[0], \n",
    "                             times_train[-1], dt_train))\n",
    "print(\"Predicting NODE solutions using %d modes for %d time steps with %.3f <= t <= %.3f and dt = %.3f\"%(\n",
    "                            state_len, true_pred_state_array.shape[0], times_predict[0], \n",
    "                            times_predict[-1], dt_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess training data (scale time and/or states, augment states if using ANODE)\n",
    "### Set up learning rate scheduler and optimizer for training of the NODE model\n",
    "\n",
    "true_state_tensor, times_tensor, init_tensor, learn_rate, optim = \\\n",
    "                NODE.preprocess_data(scale_states=scale_states, scale_time=scale_time, augmented=augmented, \n",
    "                        lr_decay=learning_rate_decay, init_lr=initial_learning_rate, opt=optimizer, \n",
    "                        scaling_method=scaling_method, aug_dim=aug_dims, \n",
    "                        decay_steps=decay_steps, decay_rate=decay_rate, staircase=staircase_opt, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "### ---- Model Training ------\n",
    "train_loss_results, train_lr, saved_ep = \\\n",
    "NODE.train_model(true_state_tensor, times_tensor, init_tensor, epochs, savedir, \\\n",
    "                 solver=solver, purpose=purpose, adjoint=use_adjoint, \\\n",
    "                 minibatch=use_minibatch, pre_trained_dir = pre_trained_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4bf934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## --- Generate NODE predictions ---\n",
    "\n",
    "predicted_states, times_predict = NODE.predict_time(times_predict, init_tensor, pre_trained_dir,)\n",
    "\n",
    "## ---- Compute Mean Square Error of predictions\n",
    "Z_pred = {}\n",
    "ctr= 0\n",
    "for key in stack_order.split(','):\n",
    "    Z_pred[key] = np.array(predicted_states)[:,ctr:ctr+nw[key]].T\n",
    "    ctr += nw[key]\n",
    "snap_pred = pod.reconstruct_from_rom(Z_pred, U_r, snap_mean, nw)\n",
    "\n",
    "\n",
    "error_vx = np.mean(np.square(snap_pred['v_x']-snap_pred_true['v_x']))\n",
    "error_vy = np.mean(np.square(snap_pred['v_y']-snap_pred_true['v_y']))\n",
    "\n",
    "print(\"\\n---- Mean Square Error of NODE predictions ----\\n\")\n",
    "print('Vx MSE: ' + str(error_vx))\n",
    "print('Vy MSE: ' + str(error_vy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_label(key):\n",
    "    if key == 'v_x':\n",
    "        return 'u'\n",
    "    elif key == 'v_y':\n",
    "        return 'v'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----- Visualize true and predicted POD coefficients -------\n",
    "\n",
    "comp = 0\n",
    "Nc = len(soln_names)\n",
    "# Visualization fluff here\n",
    "fig, ax = plt.subplots(nrows=Nc,ncols=3,figsize=(15,10))\n",
    "mnum = comp\n",
    "for iy, key in enumerate(soln_names):\n",
    "    for ix in range(3):\n",
    "        tt = ax[iy,ix].plot(times_predict[:],true_pred_state_array[:,mnum+ix],label='True',marker='o',\n",
    "                        markevery=100, markersize=8)\n",
    "        # Visualization of modal evolution using NODE\n",
    "        ln, = ax[iy,ix].plot(times_predict[:],predicted_states[:,mnum+ix],label='PODNODE',color='orange',marker='D',\n",
    "                        markevery=150, markersize=8)    \n",
    "\n",
    "        ax[iy,ix].set_xlabel('Time (seconds)', fontsize=18)\n",
    "        sv = set_label(key)+', mode '+str(comp+ix)\n",
    "        ax[iy,ix].set_ylabel(sv,fontsize=18)\n",
    "        ax[iy,ix].legend(fontsize=14)\n",
    "    mnum = mnum + nw[key]\n",
    "fig.suptitle(\"POD coefficients of the HFM and PODNODE solutions for 2D Burgers' equations\", fontsize=20)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.99])\n",
    "\n",
    "# os.chdir(figdir)\n",
    "# plt.savefig('burgers_podnode_coeff_tskip%d_oskip%d_epochs%d'%(snap_incr,pred_incr,epochs),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "plt.semilogy(range(epochs), train_loss_results, label='Training')\n",
    "if use_minibatch:\n",
    "    plt.semilogy(range(epochs), val_loss_results,label='Validation')\n",
    "plt.legend(fontsize=16); plt.xticks(fontsize=14); plt.yticks(fontsize=14)\n",
    "plt.ylabel('$\\log$ | MSE Loss |',fontsize=16); plt.xlabel('epochs',fontsize=16)\n",
    "\n",
    "# os.chdir(figdir)\n",
    "# plt.savefig('burgers_podnode_train_loss_epochs%d.pdf'%(epochs),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48df61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize PODNODE and HFM solutions\n",
    "\n",
    "ky = soln_names[0]\n",
    "itime=767\n",
    "vmin = np.minimum(snap_pred[ky][:,itime].min(),snap_pred_true[ky][:,itime].min())\n",
    "vmax = np.maximum(snap_pred[ky][:,itime].max(),snap_pred_true[ky][:,itime].max())\n",
    "\n",
    "fig,axs = plt.subplots(1, 2, figsize=(10,6), constrained_layout=True)\n",
    "cf = axs[0].tripcolor(nodes[:, 0], nodes[:, 1],triangles, snap_pred[ky][:,itime], \n",
    "                   cmap=plt.cm.jet, shading='gouraud', vmin=vmin, vmax=vmax)\n",
    "axs[0].axis('equal'); axs[0].axis('off')\n",
    "axs[0].set_title('PODNODE $\\mathbf{%s}$ solution\\n at t=%.2f seconds'%(set_label(ky),times_predict[itime]))\n",
    "\n",
    "\n",
    "cf = axs[1].tripcolor(nodes[:, 0], nodes[:, 1],triangles, snap_pred_true[ky][:,itime], \n",
    "                   cmap=plt.cm.jet, shading='gouraud', vmin=vmin, vmax=vmax)\n",
    "axs[1].axis('equal'); axs[1].axis('off')\n",
    "axs[1].set_title('HFM $\\mathbf{%s}$ solution\\n at t=%.2f seconds'%(set_label(ky),times_predict[itime]))\n",
    "fig.colorbar(cf, ax=axs[:], shrink=0.7, location='bottom', pad=0.04, aspect=30)\n",
    "\n",
    "# os.chdir(figdir)\n",
    "# plt.savefig('burgers_podnode_%s_t%.2f_tskip%d_oskip%d.pdf'%(ky,times_predict[itime],snap_incr,pred_incr),bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79118b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize solution error\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.tripcolor(nodes[:, 0], nodes[:, 1],triangles, \n",
    "                    snap_pred[ky][:,itime]-snap_pred_true[ky][:,itime], \n",
    "                    cmap=plt.cm.jet, shading='flat')\n",
    "plt.axis('equal'); plt.axis('off')\n",
    "# rpu.viz_err(snap_pred[ky][:,itime],snap_pred_true[ky][:,itime],nodes,triangles)\n",
    "\n",
    "plt.title('PODNODE $\\mathbf{%s}$ error\\n at t=%.2f'%(ky,times_predict[itime]))\n",
    "plt.colorbar(shrink=0.9, aspect=20, pad=0.05)\n",
    "\n",
    "# os.chdir(figdir)\n",
    "# plt.savefig('burgers_podnode_%s_err_t%.2f_tskip%d_oskip%d.pdf'%(ky,times_predict[itime],snap_incr,pred_incr),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d71018",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---- Compute spatial RMS/Relative error\n",
    "reload(nd)\n",
    "reload(pu)\n",
    "metric = 'rel'\n",
    "err = NODE.compute_error(snap_pred_true, snap_pred, soln_names, metric=metric)\n",
    "\n",
    "vstring = {}\n",
    "for key in soln_names:\n",
    "    vstring[key] = set_label(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "ky1 = soln_names[0]; ky2 = soln_names[1]; \n",
    "t_unit = 'seconds'\n",
    "tseries = times_predict\n",
    "freq = tseries.size//20\n",
    "\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(tseries[:], err[ky1][:], 'r-s', markersize=8,\n",
    "                label='$\\mathbf{%s}$'%(vstring[ky1]),lw=2, markevery=freq)\n",
    "ymax_ax1 = err[ky1][:].max()\n",
    "ax1.set_xlabel('Time (%s)'%t_unit);lg=plt.legend(ncol=2, fancybox=True,)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(tseries[:], err[ky2][:], 'b-o', markersize=8,\n",
    "                label='$\\mathbf{%s}$'%(vstring[ky2]), lw=2, markevery=freq)\n",
    "ymax_ax2 = err[ky2][:].max()\n",
    "ax2.set_xlabel('Time (%s)'%t_unit);lg=plt.legend(ncol=2, fancybox=True,)\n",
    "if metric == 'rms':\n",
    "    fig.suptitle('Spatial RMS errors of PODNODE NIROM solutions for 2D Burgers example',fontsize=18)\n",
    "elif metric == 'rel':\n",
    "    fig.suptitle('Relative errors of PODNODE NIROM solutions for 2D Burgers example',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25b0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----- Save predicted solutions -------\n",
    "save_nirom_solutions = False\n",
    "\n",
    "if save_nirom_solutions:\n",
    "    os.chdir(nodedir)\n",
    "    print(\"Saving results in %s\"%(os.getcwd()))\n",
    "\n",
    "    np.savez_compressed('burgers2d_online_node', \n",
    "                        v_x=snap_pred['v_x'], v_y=snap_pred['v_y'],\n",
    "                        time=times_predict, loss=train_loss_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
