{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308436a5",
   "metadata": {},
   "source": [
    "### Notebook for constructiong POD-NODE NIROM approximation for a flow around a cylinder example\n",
    "\n",
    "A collection of high-fidelity snapshots are generated that sufficiently capture the time-dynamics of the simulation. POD is adopted to define a reduced basis space for the high-fidelity snaphosts. The evolution of the time dynamics in the POD-latent space is modeled using Neural ODEs (NODE).  \n",
    "\n",
    "Adaptive Hydraulics (AdH) is used as the high-fidelity model for simulating two real world flow examples governed by the 2d depth-averaged shallow water equations.\n",
    "\n",
    "#### Note\n",
    "This notebook serves as an example of how to set up and evaluate a PODNODE model for the given dataset. However, in order to attain a desirable level of prediction accuracy, the training time is high. Please refer to \n",
    "```\n",
    "S. Dutta, P. Rivera-casillas, and M. W. Farthing, “Neural Ordinary Differential Equations for Data-Driven Reduced Order Modeling of Environmental Hydrodynamics,” in Proceedings of the AAAI 2021 Spring Symposium on Combining Artificial Intelligence and Machine Learning with Physical Sciences, 2021. \n",
    "arXiv:2104.13962 [cs.LG]\n",
    "```\n",
    "for model configuration details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f787c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import scipy\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import platform\n",
    "print(\"Python \"+str(platform.python_version()))\n",
    "import importlib\n",
    "from importlib import reload as reload\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow \"+ str(tf.__version__))\n",
    "if tf.__version__ == '1.15.0':\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "elif tf.__version__.split('.')[0] == 2: \n",
    "    print(\"Setting Keras backend datatype\")\n",
    "    tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "from tfdiffeq import odeint,odeint_adjoint\n",
    "from tfdiffeq.adjoint import odeint as adjoint_odeint\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "np.random.seed(0)\n",
    "\n",
    "basedir   = os.getcwd()\n",
    "srcdir = os.path.join(basedir,'../pynirom/')\n",
    "workdir   = os.path.join(basedir,'../examples/')\n",
    "datadir   = os.path.join(basedir,'../data/')\n",
    "figdir    = os.path.join(basedir,'../figures/podnode')\n",
    "nodedir   = os.path.join(basedir,'../data/')\n",
    "\n",
    "import pynirom\n",
    "from pynirom.pod import pod_utils as pod\n",
    "from pynirom.utils import data_utils as du\n",
    "from pynirom.node import main as nd\n",
    "from pynirom.node import plotting as pu\n",
    "from pynirom.node import node as node\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fff0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu:0'           # select gpu:# or cpu:#\n",
    "purpose= 'retrain'           #'train' to train a new model, \n",
    "                           # 'retrain' to start training from an existing model, and \n",
    "                           # 'eval' to load a pre-trained model for evaluation \n",
    "stacking = True            #If True, Specify new stacking order of latent space vector\n",
    "stack_order = 'S_dep,S_vx,S_vy'  #If stacking = True, specify the stacking order of the latent space vector\n",
    "scale_time = True          #Scale time or not (Normalize)\n",
    "scale_states = False       #Scale states \n",
    "scaling_method = 'maxabs'  #Scaling method: 'centered', 'minmax' or 'maxabs'\n",
    "augmented,aug_dims = (False,5) #Augmented or not and size of augmentation\n",
    "N_layers = int(1)          #Only four layers supported as of now.\n",
    "N_neurons = int(256)       #Number of neurons per layer\n",
    "act_f = 'linear'             #Activation Function ('linear', 'tanh', 'sigmoid',...), default='tanh'\n",
    "learning_rate_decay = True #Use decaying learning rate or not\n",
    "initial_learning_rate = float(0.001) #If 'learning_rate_decay = False' then this is the fixed learning rate\n",
    "decay_steps = int(5001)    #Number of steps for learning rate decay\n",
    "decay_rate = float(0.5)    #Rate of learning rate decay\n",
    "staircase_opt = True       #True for staircase decay and False for exponential\n",
    "optimizer = 'RMSprop'      #See pynirom.node.node.set_optimizer() for options\n",
    "use_adjoint = False        #Use adjoint method or not\n",
    "solver = 'rk4'             #Specify ODE solver. See tfdiffeq README for available options \n",
    "use_minibatch, batch_size = (False,64) #Use minibatch or not and batch size\n",
    "epochs = int(100)           #Number of epochs of training\n",
    "\n",
    "\n",
    "print(\"\\n***** Runtime parameters: ******\\n\")\n",
    "print(f'Mode = {purpose}, Scaling = {scale_states}, Augmenting = {augmented}, Adjoint = {use_adjoint}')\n",
    "print(f'Solver = {solver}, Optimizer = {optimizer}, Stacking order = {stack_order}, Epochs = {epochs}')\n",
    "print(f'# Layers = {N_layers}, # Neurons per layer = {N_neurons}, Activation fn = {act_f}')\n",
    "if use_minibatch:\n",
    "    print(f'Use minibatch = {use_minibatch}, Batch size = {batch_size}')\n",
    "if learning_rate_decay:\n",
    "    print(f'Init LR = {initial_learning_rate}, # LR decay steps = {decay_steps}, LR decay rate = {decay_rate}')\n",
    "else:\n",
    "    print(f'Fixed LR = {initial_learning_rate}')\n",
    "print('**********************************\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236eb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ Import Snapshot data -------------------\n",
    "model_sw = 'RED'\n",
    "\n",
    "if model_sw =='SD':\n",
    "    data = np.load(datadir + 'san_diego_tide_snapshots_T4.32e5_nn6311_dt25.npz')\n",
    "    mesh = np.load(datadir + 'san_diego_mesh.npz')\n",
    "elif model_sw == 'RED':\n",
    "    data = np.load(datadir + 'red_river_inset_snapshots_T7.0e4_nn12291_dt10.npz')\n",
    "    mesh = np.load(datadir + 'red_river_mesh.npz')\n",
    "\n",
    "savedir = nodedir+model_sw+'/current'\n",
    "pre_trained_dir = savedir+'/model_weights/' #If 'eval' specify path for pretrained model\n",
    "\n",
    "print('HFM data has {0} snapshots of dimension {1} for h,u and v, spanning times [{2}, {3}]'.format(\n",
    "                    data['T'].shape[0],data['S_dep'].shape[0],\n",
    "                    data['T'][0], data['T'][-1]))\n",
    "\n",
    "\n",
    "## ------- Prepare training snapshots ----------------\n",
    "print('\\n-------Prepare training and testing data---------')\n",
    "soln_names = ['S_dep', 'S_vx', 'S_vy']\n",
    "nodes = mesh['nodes'];  \n",
    "triangles = mesh['triangles']; \n",
    "\n",
    "snap_start = 100\n",
    "if model_sw == 'SD':\n",
    "    T_end = 50*3600   ### 50 hours in seconds\n",
    "    snap_incr = 4\n",
    "elif model_sw == 'RED':\n",
    "    T_end = 3.24e4    ### 9 hours in seconds\n",
    "    snap_incr = 3\n",
    "\n",
    "snap_train, times_train = du.prepare_data(data, soln_names, start_skip=snap_start, T_end=T_end, incr=snap_incr)\n",
    "print('Using {0} training snapshots for time interval [{1:.3f},{2:.3f}] hours'.format(times_train.shape[0],\n",
    "                                        times_train[0]/3600, times_train[-1]/3600))\n",
    "\n",
    "## ------- Prepare testing snapshots ----------------\n",
    "pred_incr = snap_incr - 2\n",
    "snap_pred_true, times_predict = du.prepare_data(data, soln_names, start_skip=snap_start, T_end=T_end, \n",
    "                                                    incr=pred_incr)\n",
    "print('Using {0} testing snapshots for time interval [{1:.3f},{2:.3f}] hours'.format(times_predict.shape[0],\n",
    "                                        times_predict[0]/3600, times_predict[-1]/3600))\n",
    "\n",
    "\n",
    "\n",
    "del data\n",
    "del mesh\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ Compute the POD basis using the training snapshots------------------\n",
    "if model_sw == 'SD':\n",
    "    trunc_lvl = 0.9999995  \n",
    "elif model_sw == 'RED':\n",
    "    trunc_lvl = 0.99\n",
    "    \n",
    "snap_norm, snap_mean, U, D, W = pod.compute_pod_multicomponent(snap_train)\n",
    "nw, U_r = pod.compute_trunc_basis(D, U, eng_cap = trunc_lvl)\n",
    "\n",
    "### ------ Compute the POD coefficients for training snapshots------------------\n",
    "Z_train = pod.project_onto_basis(snap_train, U_r, snap_mean)\n",
    "\n",
    "\n",
    "### ------ Compute the POD coefficients for the truth snapshots on the prediction interval------------------\n",
    "Z_pred_true = pod.project_onto_basis(snap_pred_true, U_r, snap_mean)\n",
    "\n",
    "npod_total = 0\n",
    "for key in soln_names:\n",
    "    npod_total+=nw[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c91a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- Setup NODE input data\n",
    "\n",
    "NODE = nd.NODEBase(device=device)\n",
    "true_state_array, true_pred_state_array, init_state, state_len, dt_train, dt_predict = \\\n",
    "        NODE.prepare_input_data(Z_train, nw, times_train, stack_order, times_predict, Z_pred_true)\n",
    "\n",
    "print(\"Training NODE using %d modes for %d time steps with %.3f <= t <= %.3f and dt = %.4f\"%(state_len,\n",
    "                             true_state_array.shape[0], times_train[0], \n",
    "                             times_train[-1], dt_train))\n",
    "print(\"Predicting NODE solutions using %d modes for %d time steps with %.3f <= t <= %.3f and dt = %.4f\"%(\n",
    "                            state_len, true_pred_state_array.shape[0], times_predict[0], \n",
    "                            times_predict[-1], dt_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess training data (scale time and/or states, augment states if using ANODE)\n",
    "### Set up learning rate scheduler and optimizer for training of the NODE model\n",
    "\n",
    "true_state_tensor, times_tensor, init_tensor, learn_rate, optim = \\\n",
    "                NODE.preprocess_data(scale_states=scale_states, augmented=augmented, \n",
    "                        lr_decay=learning_rate_decay, init_lr=initial_learning_rate, opt=optimizer, \n",
    "                        scaling_method=scaling_method, aug_dim=aug_dims, \n",
    "                        decay_steps=decay_steps, decay_rate=decay_rate, staircase=staircase_opt, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- Model Training ------\n",
    "\n",
    "train_loss_results, train_lr, saved_ep = \\\n",
    "         NODE.train_model(true_state_tensor, times_tensor, init_tensor, epochs, savedir,\n",
    "                    solver=solver, purpose=purpose, adjoint=use_adjoint, minibatch=use_minibatch,\n",
    "                         pre_trained_dir = pre_trained_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b150bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## --- Generate NODE predictions ---\n",
    "\n",
    "predicted_states, times_predict = NODE.predict_time(times_predict, init_tensor, pre_trained_dir,)\n",
    "\n",
    "## ---- Compute Mean Square Error of predictions\n",
    "Z_pred = {}\n",
    "ctr= 0\n",
    "for key in stack_order.split(','):\n",
    "    Z_pred[key] = np.array(predicted_states)[:,ctr:ctr+nw[key]].T\n",
    "    ctr += nw[key]\n",
    "snap_pred = pod.reconstruct_from_rom(Z_pred, U_r, snap_mean, nw)\n",
    "\n",
    "error_h = np.mean(np.square(snap_pred['S_dep']-snap_pred_true['S_dep']))\n",
    "error_vx = np.mean(np.square(snap_pred['S_vx']-snap_pred_true['S_vx']))\n",
    "error_vy = np.mean(np.square(snap_pred['S_vy']-snap_pred_true['S_vy']))\n",
    "\n",
    "print(\"\\n---- Mean Square Error of NODE predictions ----\\n\")\n",
    "print('H MSE: ' + str(error_h))\n",
    "print('Vx MSE: ' + str(error_vx))\n",
    "print('Vy MSE: ' + str(error_vy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b175da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_label(key):\n",
    "    if key == 'S_vx':\n",
    "        return 'u'\n",
    "    elif key == 'S_vy':\n",
    "        return 'v'\n",
    "    elif key == 'S_dep':\n",
    "        return 'h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23761ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Visualize true and predicted POD coefficients -------\n",
    "\n",
    "comp = 0\n",
    "\n",
    "# Visualization fluff here\n",
    "fig, ax = plt.subplots(nrows=3,ncols=1,figsize=(8,15))\n",
    "mnum = comp\n",
    "for i, key in enumerate(soln_names):\n",
    "    tt = ax[i].plot(times_predict[:],true_pred_state_array[:,mnum],label='True',marker='o',markevery=20)\n",
    "    # Visualization of modal evolution using NODE\n",
    "    ln, = ax[i].plot(times_predict[:],predicted_states[:,mnum],label='NODE',color='orange',marker='D',\n",
    "                     markevery=25)\n",
    "    mnum = mnum + nw[key]\n",
    "\n",
    "    ax[i].set_xlabel('Time', fontsize=18)\n",
    "    sv = set_label(key)+', mode '+str(comp)\n",
    "    ax[i].set_ylabel(sv,fontsize=18)\n",
    "    ax[i].legend(fontsize=14)\n",
    "fig.suptitle(\"POD coefficients of the HFM and NODE solutions\", fontsize=20)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---- Compute spatial RMS/Relative error\n",
    "\n",
    "metric = 'rms'\n",
    "err = NODE.compute_error(snap_pred_true, snap_pred, soln_names, metric=metric)\n",
    "\n",
    "vstring = {}\n",
    "for key in soln_names:\n",
    "    vstring[key] = set_label(key)\n",
    "\n",
    "## ---- Visualize computed error metric\n",
    "pu.plot_NODE_err(err, times_predict/3600, soln_names, vstring, metric=metric, unit='hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85865708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----- Save predicted solutions -------\n",
    "save_nirom_solutions = False\n",
    "\n",
    "if save_nirom_solutions:\n",
    "    os.chdir(nodedir)\n",
    "    print(\"Saving results in %s\"%(os.getcwd()))\n",
    "    \n",
    "#     if model_sw == 'RED':\n",
    "#         model = 'Red'\n",
    "#     elif model_sw == 'SD':\n",
    "#         model = 'SD'\n",
    "    \n",
    "    np.savez_compressed('%s_online_node'%(model_sw), S_dep=snap_pred['S_dep'],S_vx = snap_pred['S_vx'], \n",
    "                        S_vy = snap_pred['S_vy'], time=times_predict, loss=train_loss_results,)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
