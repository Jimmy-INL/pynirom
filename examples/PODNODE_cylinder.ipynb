{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308436a5",
   "metadata": {},
   "source": [
    "### Notebook for constructiong POD-NODE NIROM approximation for a flow around a cylinder example\n",
    "\n",
    "A collection of high-fidelity snapshots are generated that sufficiently capture the time-dynamics of the simulation. POD is adopted to define a reduced basis space for the high-fidelity snaphosts. The evolution of the time dynamics in the POD-latent space is modeled using Neural ODEs (NODE).  \n",
    "\n",
    "OpenFOAM is used as the high-fidelity model for simulating flow around a cylinder governed by incompressible 2D Navier Stokes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f787c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.0\n",
      "Tensorflow 2.4.1\n",
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 04:06:30.940491: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "### Loading modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import scipy\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import platform\n",
    "print(\"Python \"+str(platform.python_version()))\n",
    "import importlib\n",
    "from importlib import reload as reload\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow \"+ str(tf.__version__))\n",
    "if tf.__version__ == '1.15.0':\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "elif tf.__version__.split('.')[0] == 2: \n",
    "    print(\"Setting Keras backend datatype\")\n",
    "    tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "from tfdiffeq import odeint,odeint_adjoint\n",
    "from tfdiffeq.adjoint import odeint as adjoint_odeint\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "np.random.seed(0)\n",
    "\n",
    "basedir   = os.getcwd()\n",
    "srcdir = os.path.join(basedir,'../pynirom/')\n",
    "workdir   = os.path.join(basedir,'../examples/')\n",
    "datadir   = os.path.join(basedir,'../data/')\n",
    "figdir    = os.path.join(basedir,'../figures')\n",
    "nodedir   = os.path.join(basedir,'../data/')\n",
    "\n",
    "modeldir = basedir\n",
    "savedir = nodedir+'cylinder/current'\n",
    "\n",
    "import pynirom\n",
    "from pynirom.pod import pod_utils as pod\n",
    "from pynirom.utils import data_utils as du\n",
    "from pynirom.node import main as nd\n",
    "from pynirom.node import plotting as pu\n",
    "from pynirom.node import node as node\n",
    "# os.chdir(workdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9de6189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Runtime parameters: ******\n",
      "\n",
      "Mode = train, Scaling = True, Augmenting = False, Adjoint = False\n",
      "Solver = rk4, Optimizer = RMSprop, Stacking order = v_x,v_y,p, Epochs = 10\n",
      "# Layers = 1, # Neurons per layer = 256, Activation fn = tanh\n",
      "Init LR = 0.001, # LR decay steps = 5001, LR decay rate = 0.5\n",
      "**********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu:0' # select gpu:# or cpu:#\n",
    "purpose= 'train' #'train' to train a new model and 'eval' to load a pre-trained model for evaluation (make sure you have the correct set of hyperparameters)\n",
    "pre_trained_dir = nodedir+'/model_weights_cyl/' #If 'eval' specify path for pretrained model\n",
    "stacking = True #stack or not\n",
    "stack_order = 'v_x,v_y,p' #If stacking = True, specify the stacking order of the latent space vector\n",
    "scale_time = False #Scale time or not (Normalize)\n",
    "scale_states = True #Scale states or not (MinMax -1,1)\n",
    "augmented,aug_dims = (False,5) #Augmented or not and size of augmentation\n",
    "N_layers = int(1.0) #Only four layers supported as of now.\n",
    "N_neurons = int(256) #Number of neurons per layer\n",
    "act_f = 'tanh'  #Activation Function ('linear', 'tanh', 'sigmoid',...), default='linear'\n",
    "learning_rate_decay = True #Use decaying learning rate or not\n",
    "initial_learning_rate = float(0.001) #If 'learning_rate_decay = False' then this will be the fixed learning rate\n",
    "decay_steps = int(5001) #Number of steps for learning rate decay\n",
    "decay_rate = float(0.5) #Rate of learning rate decay\n",
    "staircase_opt = True  #True for staircase decay and False for exponential\n",
    "optimizer = 'RMSprop' #Adam and RMSprop optimizers are supported as of now\n",
    "use_adjoint = False       #Use adjoint method or not\n",
    "solver = 'rk4'     #Specify ODE solver. See tfdiffeq README for available options \n",
    "use_minibatch, batch_size = (False,256) #Use minibatch or not and batch size\n",
    "epochs = int(10)     #Number of epochs of training\n",
    "\n",
    "\n",
    "print(\"\\n***** Runtime parameters: ******\\n\")\n",
    "print(f'Mode = {purpose}, Scaling = {scale_states}, Augmenting = {augmented}, Adjoint = {use_adjoint}')\n",
    "print(f'Solver = {solver}, Optimizer = {optimizer}, Stacking order = {stack_order}, Epochs = {epochs}')\n",
    "print(f'# Layers = {N_layers}, # Neurons per layer = {N_neurons}, Activation fn = {act_f}')\n",
    "print(f'Init LR = {initial_learning_rate}, # LR decay steps = {decay_steps}, LR decay rate = {decay_rate}')\n",
    "print('**********************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236eb93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HFM data has 3001 snapshots of dimension 14605 for h,u and v, spanning times [0.0, 6.0]\n",
      "\n",
      "-------Prepare training and testing data---------\n",
      "Using 313 training snapshots for time interval [2.5,4.996]\n",
      "Using 1750 testing snapshots for time interval [2.5,5.998]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ------ Import Snapshot data -------------------\n",
    "data = np.load(datadir + 'cylinder_Re100.0_Nn14605_Nt3001.npz')\n",
    "mesh = np.load(datadir + 'OF_cylinder_mesh_Nn14605_Ne28624.npz')\n",
    "\n",
    "print('HFM data has {0} snapshots of dimension {1} for h,u and v, spanning times [{2}, {3}]'.format(\n",
    "                    data['time'].shape[0],data['p'].shape[0],\n",
    "                    data['time'][0], data['time'][-1]))\n",
    "\n",
    "\n",
    "## ------- Prepare training snapshots ----------------\n",
    "print('\\n-------Prepare training and testing data---------')\n",
    "soln_names = ['p', 'v_x', 'v_y']\n",
    "nodes = mesh['nodes'];  node_ind = mesh['node_ind']\n",
    "triangles = mesh['elems']; elem_ind = mesh['elem_ind']\n",
    "snap_start = 1250\n",
    "T_end = 5.0        ### 5 seconds\n",
    "snap_incr = 4\n",
    "\n",
    "snap_train, times_train = du.prepare_data(data, soln_names, start_skip=1250, T_end=5.0, incr=snap_incr)\n",
    "print('Using {0} training snapshots for time interval [{1},{2}]'.format(times_train.shape[0],\n",
    "                                        times_train[0], times_train[-1]))\n",
    "\n",
    "## ------- Prepare testing snapshots ----------------\n",
    "pred_incr = snap_incr -3\n",
    "snap_pred_true, times_predict = du.prepare_data(data, soln_names, start_skip=snap_start, incr=pred_incr)\n",
    "print('Using {0} testing snapshots for time interval [{1},{2}]'.format(times_predict.shape[0],\n",
    "                                        times_predict[0], times_predict[-1]))\n",
    "\n",
    "\n",
    "\n",
    "del data\n",
    "del mesh\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bee035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p truncation level for 99.0% = 5, \\sigma_6 = 17.58326064444933\n",
      "v_x truncation level for 99.0% = 8, \\sigma_9 = 10.971372231083336\n",
      "v_y truncation level for 99.0% = 7, \\sigma_8 = 13.390899418495513\n"
     ]
    }
   ],
   "source": [
    "### ------ Compute the POD basis using the training snapshots------------------\n",
    "trunc_lvl = 0.99\n",
    "snap_norm, snap_mean, U, D, W = pod.compute_pod_multicomponent(snap_train)\n",
    "nw, U_r = pod.compute_trunc_basis(D, U, eng_cap = trunc_lvl)\n",
    "\n",
    "### ------ Compute the POD coefficients for training snapshots------------------\n",
    "Z_train = pod.project_onto_basis(snap_train, U_r, snap_mean)\n",
    "\n",
    "\n",
    "### ------ Compute the POD coefficients for the truth snapshots on the prediction interval------------------\n",
    "Z_pred_true = pod.project_onto_basis(snap_pred_true, U_r, snap_mean)\n",
    "\n",
    "npod_total = 0\n",
    "for key in soln_names:\n",
    "    npod_total+=nw[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45c91a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NODE using 20 modes for 313 time steps with 2.500 <= t <= 4.996 and dt = 0.0080\n",
      "Predicting NODE solutions using 20 modes for 1750 time steps with 2.500 <= t <= 5.998 and dt = 0.0020\n"
     ]
    }
   ],
   "source": [
    "### Setup NODE input data\n",
    "\n",
    "reload(nd)\n",
    "NODE = nd.NODEBase(device=device)\n",
    "true_state_array, true_pred_state_array, init_state, state_len, dt_train, dt_predict = \\\n",
    "        NODE.prepare_input_data(Z_train, nw, times_train, stack_order, times_predict, Z_pred_true)\n",
    "\n",
    "print(\"Training NODE using %d modes for %d time steps with %.3f <= t <= %.3f and dt = %.4f\"%(state_len,\n",
    "                             true_state_array.shape[0], times_train[0], \n",
    "                             times_train[-1], dt_train))\n",
    "print(\"Predicting NODE solutions using %d modes for %d time steps with %.3f <= t <= %.3f and dt = %.4f\"%(\n",
    "                            state_len, true_pred_state_array.shape[0], times_predict[0], \n",
    "                            times_predict[-1], dt_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ec42e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(node)\n",
    "### Preprocess training data (scale time and/or states, augment states if using ANODE)\n",
    "### Set up learning rate scheduler and optimizer for training of the NODE model\n",
    "\n",
    "true_state_tensor, times_tensor, init_state, learn_rate, optim = \\\n",
    "                NODE.preprocess_data(scale_states=scale_states, augmented=augmented, \n",
    "                        lr_decay=learning_rate_decay, init_lr=initial_learning_rate, opt=optimizer, \n",
    "                        scaling_method='centered', aug_dim=aug_dims, \n",
    "                        decay_steps=decay_steps, decay_rate=decay_rate, staircase=staircase_opt, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cddb76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------Begin training---------\n",
      "\n",
      "Epoch 1: Loss = 0.878705, LR = 0.001000\n",
      "\n",
      "Epoch 2: Loss = 0.506129, LR = 0.001000\n",
      "\n",
      "******Saving model state. Epoch 2******\n",
      "\n",
      "Epoch 3: Loss = 0.376773, LR = 0.001000\n",
      "\n",
      "Epoch 4: Loss = 0.329251, LR = 0.001000\n",
      "\n",
      "******Saving model state. Epoch 4******\n",
      "\n",
      "Epoch 5: Loss = 0.305369, LR = 0.001000\n",
      "\n",
      "Epoch 6: Loss = 0.288611, LR = 0.001000\n",
      "\n",
      "******Saving model state. Epoch 6******\n",
      "\n",
      "Epoch 7: Loss = 0.279439, LR = 0.001000\n",
      "\n",
      "Epoch 8: Loss = 0.275501, LR = 0.001000\n",
      "\n",
      "******Saving model state. Epoch 8******\n",
      "\n",
      "Epoch 9: Loss = 0.273509, LR = 0.001000\n",
      "\n",
      "Epoch 10: Loss = 0.271870, LR = 0.001000\n",
      "\n",
      "******Saving model state. Epoch 10******\n",
      "\n",
      "****Total training time = 15.964924335479736****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ---- Model Training ------\n",
    "reload(node)\n",
    "reload(nd)\n",
    "train_loss_results, train_lr, saved_ep = \\\n",
    "         NODE.train_model(true_state_tensor, times_tensor, init_state, epochs, savedir,\n",
    "                    solver=solver, purpose=purpose, adjoint=use_adjoint, minibatch=use_minibatch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
